{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamiepratt/lingq/blob/main/spacy_bulk_parse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj-Dqzx8oeXg"
      },
      "source": [
        "### Access Google Drive Directory and Google Sheets\n",
        "\n",
        "Mount your Google Drive to access files from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWKeAINWoeXg",
        "outputId": "0e2e6a7b-bb8d-4afe-ab3a-7739e29b33d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvn0VWT-oeXg"
      },
      "source": [
        "Specify the directory in your Google Drive that you want to access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PrW1G-yJoeXh",
        "outputId": "7a369812-0dc4-4e50-a6c0-e76cc6df55dd"
      },
      "source": [
        "# Replace 'your-directory-path' with your specific directory path\n",
        "sub_dir = \"lingq_texts/pl/Daily Polish Story 41-50/\"  #@param {type:\"string\"}\n",
        "drive_directory = '/content/drive/MyDrive/' + sub_dir\n",
        "drive_directory"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n"
      ],
      "metadata": {
        "id": "U4eJuxZ1us2s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "#@title Choose a language model\n",
        "model = \"pl_core_news_lg\" #@param [\"pl_core_news_lg\", \"ca_core_news_sm\", \"da_core_news_sm\", \"de_core_news_sm\", \"el_core_news_sm\", \"en_core_web_sm\", \"es_core_news_sm\", \"fi_core_news_sm\", \"fr_core_news_sm\", \"hr_core_news_sm\", \"it_core_news_sm\", \"ja_core_news_sm\", \"ko_core_news_sm\", \"lt_core_news_sm\", \"mk_core_news_sm\", \"nb_core_news_sm\", \"nl_core_news_sm\", \"pt_core_news_sm\", \"ro_core_news_sm\", \"sl_core_news_sm\", \"sv_core_news_sm\", \"ru_core_news_sm\", \"uk_core_news_sm\", \"xx_ent_wiki_sm\", \"xx_sent_ud_sm\", \"zh_core_web_sm\"]\n",
        "!python -m spacy download {model}\n",
        "\n",
        "spacy.prefer_gpu()\n",
        "\n",
        "nlp = spacy.load(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9fn8lHY0ctJ",
        "outputId": "21f98820-44a2-4410-894b-a21e12ec23be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-23 07:48:24.500476: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-23 07:48:24.500538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-23 07:48:24.501756: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-23 07:48:25.772201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting pl-core-news-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_lg-3.6.0/pl_core_news_lg-3.6.0-py3-none-any.whl (573.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.7/573.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from pl-core-news-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->pl-core-news-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: pl-core-news-lg\n",
            "Successfully installed pl-core-news-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pl_core_news_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wohayCZBoeXh"
      },
      "source": [
        "### Step 3: Iterate Through Files and Output Content of .txt Files\n",
        "\n",
        "Define a function to iterate through files in a directory and print the content of `.txt` files."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Świetnie! Tak Kasia opowiadała o tym, że była głodna i zrobiła sobie kanapkę. Teraz czas na pytania i odpowiedzi. Jak zawsze zachęcam do głośnego odpowiadania na pytania. Ale jeśli wolisz, możesz tylko posłuchać jak ja na nie odpowiadam. Zaczynajmy! Kasia była głodna. Czy Kasi chciało się jeść? Tak, ona była głodna, czyli chciało jej się jeść. Czy Kasia była najedzona? Nie, ona nie była najedzona. Ona była głodna. Kto był głodny? Kasia. Ona była głodna. Kasia poszła do kuchni i otworzyła lodówkę. Gdzie poszła Kasia? Ona poszła do kuchni. Czy Kasia otworzyła okno w kuchni? Nie, ona nie otworzyła okna. Co otworzyła Kasia? Lodówkę. Ona otworzyła lodówkę. Czy Kasia otworzyła czy zamknęła lodówkę? Otworzyła. Ona otworzyła lodówkę. Ona nie zamknęła lodówki. W lodówce był ser, kiełbasa i masło. Czy w lodówce były owoce? Nie, w lodówce nie było owoców. Co było w lodówce? Ser, kiełbasa i masło. W lodówce był ser, kiełbasa i masło. Czy ser był na stole czy w lodówce? W lodówce. Ser był w lodówce. Kasia nie miała ochoty na kiełbasę. Czy Kasia chciała zjeść kiełbasę? Nie, ona nie chciała kiełbasy. Ona nie miała ochoty na kiełbasę. Na co nie miała ochoty Kasia? Na kiełbasę. Ona nie miała ochoty na kiełbasę. Kto nie miał ochoty na kiełbasę? Kasia. Ona nie miała ochoty na kiełbasę. Ona wzięła ser i masło. Co wzięła z lodówki Kasia? Ser i masło. Ona wzięła ser i masło. Czy Kasia wzięła kiełbasę? Nie, ona nie wzięła kiełbasy. Ona wzięła ser i masło. Kto wziął ser i masło? Kasia. Kasia wzięła ser i masło. Kasia otworzyła szafkę. Czy Kasia zamknęła szafkę? Nie, ona nie zamknęła szafki. Ona otworzyła szafkę. Czy Kasia otworzyła okno? Nie, nie okno. Ona otworzyła szafkę. Co otworzyła Kasia? Szafkę. Ona otworzyła szafkę. W szafce był chleb. Czy szafka była pusta? Nie, szafka nie była pusta. W szafce był chleb. Czy w szafce była kiełbasa? Nie, w szafce nie było kiełbasy. Co było w szafce? Chleb. W szafce był chleb. Kasia wzięła nóż i ukroiła dwie kromki chleba. Czy Kasia ukroiła dwa kawałki chleba? Tak, ona ukroiła dwie kromki chleba, czyli dwa kawałki chleba. Czym Kasia ukroiła chleb? Nożem. Ona wzięła nóż i ukroiła chleb. Ile kromek chleba ukroiła Kasia? Dwie czy trzy? Dwie. Ona ukroiła dwie kromki chleba. Czy Kasia ukroiła cztery kromki chleba? Nie, ona nie ukroiła czterech kromek chleba. Ona ukroiła tylko dwie kromki chleba. Potem ukroiła plasterek sera. Czy Kasia ukroiła cienki kawałek sera? Tak, ona ukroiła plasterek sera, czyli cienki kawałek sera. Plasterek to cienki kawałek czegoś. Może być plasterek sera, plasterek kiełbasy, plasterek szynki. Czy Kasia najpierw ukroiła dwie kromki chleba, a potem plasterek sera? Tak, ona ukroiła najpierw chleb, a potem plasterek sera. Co ukroiła Kasia? Ser. Ona ukroiła plasterek sera. Kasia posmarowała chleb masłem. Czym Kasia posmarowała chleb? Masłem. Ona posmarowała chleb masłem. Co Kasia posmarowała masłem? Chleb. Ona posmarowała chleb masłem. Co zrobiła Kasia? Ona posmarowała chleb masłem. Kasia włożyła ser między posmarowane kawałki chleba. Gdzie Kasia włożyła ser? Między chleb. Ona włożyła ser między posmarowane kawałki chleba. Czy Kasia włożyła kiełbasę między kawałki chleba? Nie, ona nie włożyła kiełbasy. Co Kasia włożyła między kawałki chleba? Ser. Ona włożyła ser między kawałki chleba. Co zrobiła Kasia? Ona włożyła ser między posmarowane kawałki chleba. Ona położyła kanapkę na talerzu. Czy Kasia położyła kanapkę na stole? Nie, ona nie położyła kanapki na stole. Gdzie Kasia położyła kanapkę? Na talerzu. Ona położyła kanapkę na talerzu. Czy Kasia położyła ciasto na talerzu? Nie, ona nie położyła ciasta na talerzu. Co Kasia położyła na talerzu? Kanapkę. Ona położyła kanapkę na talerzu. Kasia usiadła przy stole i zjadła kanapkę. Czy Kasia usiadła obok stołu? Tak, ona usiadła przy stole, czyli obok stołu. Czy Kasia zjadła ciasto? Nie, ona nie zjadła ciasta. Co zjadła Kasia? Kanapkę. Ona zjadła kanapkę. Co zrobiła Kasia? Ona usiadła przy stole i zjadła kanapkę. Doskonale. W ten sposób kończy się dzisiejsza historyjka. Kończą się również pytania i odpowiedzi. Posłuchaj całej lekcji jeszcze kilka razy, a potem zapraszam na dalszy ciąg opowiadania o Kasi. Jeśli chcesz dowiedzieć się, co wydarzyło się potem, posłuchaj następnej historyjki po polsku. Pa, pa!\")\n",
        "for s in doc.sents:\n",
        "  if len(s) < 4:\n",
        "    print(s.text)\n",
        "\n"
      ],
      "metadata": {
        "id": "qyR7cc7QulPw",
        "outputId": "dbb30823-674b-4b9c-e559-72ac86ff71b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Świetnie!\n",
            "Zaczynajmy!\n",
            "Kasia.\n",
            "Lodówkę.\n",
            "Otworzyła.\n",
            "W lodówce.\n",
            "Na kiełbasę.\n",
            "Kasia.\n",
            "Kasia.\n",
            "Szafkę.\n",
            "Chleb.\n",
            "Nożem.\n",
            "Ser.\n",
            "Masłem.\n",
            "Chleb.\n",
            "Między chleb.\n",
            "Ser.\n",
            "Na talerzu.\n",
            "Kanapkę.\n",
            "Kanapkę.\n",
            "Doskonale.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see https://github.com/jamiepratt/lingq/blob/main/spacy_experiments.ipynb for how I calculated this:\n",
        "data_cols = [\"filename\", \"directory\", \"token_no\", \"term\", \"lemma\", \"pos\", \"part of speech\",\n",
        "             \"case\", \"gender\", \"number\",\n",
        "             \"sentence\", \"morph\", \"tags\"]\n",
        "\n",
        "pos_to_skip = [\"PUNCT\", \"CCONJ\", \"SPACE\", \"X\", \"INTJ\", \"SYM\"]\n",
        "\n",
        "(data_cols[3], data_cols[7])"
      ],
      "metadata": {
        "id": "asHbDHSDwTQJ",
        "outputId": "3877c355-34c3-426f-ccc6-ea0ad094b1b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('term', 'case')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1jr_fNaoeXh"
      },
      "source": [
        "import os\n",
        "\n",
        "def get_morph_prop(token, propname):\n",
        "  prop_arr = token.morph.get(propname)\n",
        "  if len(prop_arr):\n",
        "    return prop_arr[0]\n",
        "  else:\n",
        "    return \"\"\n",
        "\n",
        "def spacy_data_from_txt_files_content(directory):\n",
        "    encountered_words = {}\n",
        "    data = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file_name in files:\n",
        "            if file_name.endswith('.txt'):\n",
        "                file_path = os.path.join(root, file_name)\n",
        "                with open(file_path, 'r') as file:\n",
        "                    print(f\"Processing contents of {file_path}:\\n\")\n",
        "                    doc = nlp(file.read())\n",
        "                    for s in doc.sents:\n",
        "                      if len(s) > 4:\n",
        "                        for t in s:\n",
        "                          if t.pos_ not in pos_to_skip:\n",
        "                            word_sentence = (t.text, t.sent.text)\n",
        "                            if word_sentence not in encountered_words:\n",
        "                              encountered_words[word_sentence] = True\n",
        "                              explained = spacy.explain(t.pos_)\n",
        "                              t_data = [file_name,\n",
        "                                        root,\n",
        "                                        t.i,\n",
        "                                        t.text,\n",
        "                                        t.lemma_,\n",
        "                                        t.pos_,\n",
        "                                        explained,\n",
        "                                        get_morph_prop(t, \"Case\"),\n",
        "                                        get_morph_prop(t, \"Gender\"),\n",
        "                                        get_morph_prop(t, \"Number\"),\n",
        "                                        t.sent.text,\n",
        "                                        f'{t.morph}',\n",
        "                                        \" \".join([explained] + f'{t.morph}'.split(\"|\"))]\n",
        "                              data.append(t_data)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1nOVUujoeXh",
        "outputId": "6ad281ab-d54f-444c-98a2-ca5b78a66f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spacy_data = spacy_data_from_txt_files_content(drive_directory)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/## 041A-Ela będzie miała dziecko.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/041B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/041C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/042A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/042B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/042C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/043A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/043B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/043C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/044A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/044B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/044C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/045A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/045B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/045C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/046A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/046B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/046C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/047A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/047B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/047C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/048A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/048B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/048C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/049A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/049C-DailyPolishStory-QA.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/050A-DailyPolishStory.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/050B-DailyPolishStory-POV.txt:\n",
            "\n",
            "Processing contents of /content/drive/MyDrive/lingq_texts/pl/Daily Polish Story 41-50/050C-DailyPolishStory-QA.txt:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "RjjEoaII6Cqf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8Zg07jxihEk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a New Google Sheet\n",
        "sh = gc.create(f'spaCy analysis of {drive_directory}')\n",
        "# Open the Google Sheet with gspread\n",
        "worksheet = sh.get_worksheet(0)  # '0' refers to the first sheet\n",
        "\n",
        "# Update the sheet with DataFrame values\n",
        "worksheet.update('A1', [data_cols] + spacy_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqxmwR9cyz3A",
        "outputId": "a08e6f15-3553-439a-aeee-368c28bbc401"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1tMr0RkF4DR6comvsSdDGYeMB1D0E1sK3VMWlt-FOHbA',\n",
              " 'updatedRange': 'Sheet1!A1:M7233',\n",
              " 'updatedRows': 7233,\n",
              " 'updatedColumns': 13,\n",
              " 'updatedCells': 94028}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wkp3hQlI6AZr"
      },
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}